{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc0e4b7-fd35-4774-8b43-6201241a5780",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dbb9f71-bf64-4ce6-8e5c-43380cb685d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['label', 'title', 'description'],\n",
      "    num_rows: 120000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['label', 'title', 'description'],\n",
      "    num_rows: 7600\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sh0416/ag_news\")\n",
    "print(dataset[\"train\"])\n",
    "print(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82921415-3572-4918-ae6c-8544b53d4be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset=dataset.map(lambda batch: {\"label\": batch[\"label\"] if batch[\"label\"] < 4 else 3}, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e54b2f-167d-495f-bbfe-f2d7d2efda80",
   "metadata": {},
   "source": [
    "# Tokenization & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d0a6258-572e-492f-b2aa-edcc4e82e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72550e5-7bf6-42af-91da-44e99b858381",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "029050c3-75d7-42f8-910e-b8245a5d270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    texts=[t + \" \" + d for t, d in zip(batch[\"title\"], batch[\"description\"])]\n",
    "    return tokenizer(texts,padding=\"max_length\",truncation=True,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ccd4360-7c8d-4006-a677-ff2b6ba359af",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(tokenize, batched=True)\n",
    "encoded_dataset = encoded_dataset.rename_column(\"label\", \"labels\")\n",
    "encoded_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2371d6-b38c-4bf3-9540-eb42e99111f6",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bd05894-a536-44d7-8000-ba1133e80010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40fa6336-8075-486d-b6b1-e1c36ba5185f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9058a4-899e-426c-be7c-8bd9e3313775",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e1466d7-b888-43f3-bbc7-72ce369b410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02c54cfb-bfb8-4311-be0e-f3343f4a6109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels=eval_pred\n",
    "    preds=np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe9ebcd-90dc-4138-b21b-332db1144fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./news_classifier\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e7c65-281a-4c72-8a79-e5e951439ad0",
   "metadata": {},
   "source": [
    "# Fine-Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9ff70-dd53-465a-ae92-74da763d338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_18724\\3467074619.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer=Trainer(\n",
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='22500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   76/22500 7:27:32 < 2260:16:21, 0.00 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer=Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d2495-909a-4b6d-9ae4-e6f06e70f025",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9ccaa-4606-483e-b40e-514ed87219a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93391b6f-878f-477d-9441-4fc28b7914de",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285bd88-c98e-45f4-80b2-f47739c0c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./bert_news_model\")\n",
    "tokenizer.save_pretrained(\"./bert_news_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c0af8f-e737-4821-a8c0-ca84a93359c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
